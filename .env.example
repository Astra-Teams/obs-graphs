# --- Project settings ---
PROJECT_NAME=obs-graph

# --- Development settings ---
# Set these to true for offline development without external services
USE_SQLITE=true
USE_MOCK_GITHUB=true
USE_MOCK_LLM=true
USE_MOCK_REDIS=true
USE_MOCK_RESEARCH_API=true

# --- API server settings ---
HOST_BIND_IP=127.0.0.1
NUM_OF_UVICORN_WORKERS=1
HOST_PORT=8000
DEV_PORT=8001
TEST_PORT=8002

# --- GitHub settings ---
# GitHub token for vault repository operations (clone, commit, push, create PR)
# Required permissions: Contents (Read+Write), Pull requests (Read+Write), Metadata (Read)
VAULT_GITHUB_TOKEN=""
OBSIDIAN_VAULT_REPO_FULL_NAME=Astra-Teams/constellations

# GitHub token for ollama-deep-researcher repository (used during Docker build)
# Required permissions: Contents (Read), Metadata (Read)
OLLAMA_DEEP_RESEARCHER_GITHUB_TOKEN=""

# --- Celery Configuration ---
CELERY_BROKER_URL=redis://redis:6379/0
CELERY_RESULT_BACKEND=redis://redis:6379/0

# --- Workflow Configuration ---
WORKFLOW_CLONE_BASE_PATH=/tmp/obsidian-workflows
WORKFLOW_DEFAULT_BRANCH=main

# --- LLM Configuration ---
# Using Ollama with llama3.2:3b model
OLLAMA_MODEL=llama3.2:3b
OLLAMA_BASE_URL=http://localhost:11434/
# OLLAMA_BASE_URL=http://host.docker.internal:11434
# Container Ollama uses lightweight model (used in dev/test when OLLAMA_BASE_URL points to container)
CONTAINER_OLLAMA_MODEL=tinyllama:1.1b

# --- Research API Configuration ---
# ollama-deep-researcher service URL (see submodules/ollama-deep-researcher)
RESEARCH_API_BASE_URL=http://ollama-deep-researcher:8000
RESEARCH_API_TIMEOUT_SECONDS=300.0

# --- Database settings ---
USE_SQLITE=true
POSTGRES_IMAGE=postgres:16-alpine
POSTGRES_HOST=db
POSTGRES_PORT=5432
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_HOST_DB=obs-graph-prod
POSTGRES_DEV_DB=obs-graph-dev
POSTGRES_TEST_DB=obs-graph-test
